{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731fb6c1-2ac7-4542-b3f7-51a83a24fd27",
   "metadata": {},
   "source": [
    "## Extensive Analysis + Visualization with Python¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd6317-7a0b-454a-b97d-f0ed9702a1d4",
   "metadata": {},
   "source": [
    "Hello friends,\n",
    "\n",
    "**Heart Disease** or **Cardiovascular disease** (CVD) is a class of diseases that involve the heart or blood vessels. Cardiovascular diseases are the leading cause of death globally. This is true in all areas of the world except Africa. Together CVD resulted in 17.9 million deaths (32.1%) in 2015. Deaths, at a given age, from CVD are more common and have been increasing in much of the developing world, while rates have declined in most of the developed world since the 1970s.\n",
    "\n",
    "So, in this kernel, I have conducted **Exploratory Data Analysis or EDA** of the heart disease dataset. **Exploratory Data Analysis or EDA** is a critical first step in analyzing a new dataset. The primary objective of EDA is to analyze the data for distribution, outliers and anomalies in the dataset. It enable us to direct specific testing of the hypothesis. It includes analysing the data to find the distribution of data, its main characteristics, identifying patterns and visualizations. It also provides tools for hypothesis generation by visualizing and understanding the data through graphical representation.\n",
    "\n",
    "I hope you learn and enjoy this kernel.\n",
    "\n",
    "**So, your upvote would be highly appreciated.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994f7ca-96b6-4b85-8fcc-fe76daf20727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed8506c1-d845-46a1-ae7d-3e1fc33a06f1",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810205f2-bfda-4dc7-aa1c-fe2a3aa38444",
   "metadata": {},
   "source": [
    "**The table of contents for this project are as follows:** -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e114fe00-b5ca-45c3-83fe-a6a12ba5caa2",
   "metadata": {},
   "source": [
    "1.Introduction to EDA\n",
    "2.Objectives of EDA\n",
    "3.Types of EDA\n",
    "4.Import libraries\n",
    "5.Import dataset\n",
    "6.Exploratory data analysis - Check shape of the dataset - Preview the dataset - Summary of dataset - Dataset description - Check data types of columns - Important points about dataset - Statistical properties of dataset - View column names\n",
    "7.Univariate analysis - Analysis of target feature variable - Findings of univariate analysis\n",
    "8.Bivariate analysis - Estimate correlation coefficients - Analysis of target and cp variable - Analysis of target and thalach variable - Findings of bivariate analysis\n",
    "9.Multivariate analysis - Heat Map - Pair Plot\n",
    "10.Dealing with missing values - Pandas isnull() and notnull() functions - Useful commands to detect missing values\n",
    "11.Check with ASSERT statement\n",
    "12.Outlier detection\n",
    "13.Conclusion\n",
    "14.References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c5cc4-c93d-457b-be49-c37f2711401b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58503e71-e662-4033-a135-36401cad66f6",
   "metadata": {},
   "source": [
    "## 1. Introduction to EDA ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b894d2-c13f-463a-bf7a-05a9f1c6f0aa",
   "metadata": {},
   "source": [
    "Several questions come to mind when we come across a new dataset. The below list shed light on some of these questions:-\n",
    "\n",
    "• What is the distribution of the dataset?\n",
    "\n",
    "• Are there any missing numerical values, outliers or anomalies in the dataset?\n",
    "\n",
    "• What are the underlying assumptions in the dataset?\n",
    "\n",
    "• Whether there exists relationships between variables in the dataset?\n",
    "\n",
    "• How to be sure that our dataset is ready for input in a machine learning algorithm?\n",
    "\n",
    "• How to select the most suitable algorithm for a given dataset?\n",
    "\n",
    "So, how do we get answer to the above questions?\n",
    "\n",
    "The answer is **Exploratory Data Analysis**. It enable us to answer all of the above questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763b08b-c78f-4b61-abd4-05ebea5b1d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c12dbca0-e6cd-4929-844d-5ea89165e53a",
   "metadata": {},
   "source": [
    "## 2. Objectives of EDA ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ffe25-2cc2-4e50-9ff5-89b5324885ab",
   "metadata": {},
   "source": [
    "The objectives of the EDA are as follows:-\n",
    "\n",
    "i. To get an overview of the distribution of the dataset.\n",
    "\n",
    "ii. Check for missing numerical values, outliers or other anomalies in the dataset.\n",
    "\n",
    "iii.Discover patterns and relationships between variables in the dataset.\n",
    "\n",
    "iv. Check the underlying assumptions in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b770321-13d9-4464-bd83-a942105c968e",
   "metadata": {},
   "source": [
    "## 3. Types of EDA ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d697869-39cb-4e5f-9bf3-8b1116f067e8",
   "metadata": {},
   "source": [
    " EDA is generally cross-classified in two ways. First, each method is either non-graphical or graphical. Second, each method is either univariate or multivariate (usually bivariate). The non-graphical methods provide insight into the characteristics and the distribution of the variable(s) of interest. So, non-graphical methods involve calculation of summary statistics while graphical methods include summarizing the data diagrammatically.\n",
    "\n",
    "There are four types of exploratory data analysis (EDA) based on the above cross-classification methods. Each of these types of EDA are described below:-\n",
    "\n",
    "**i. Univariate non-graphical EDA**\n",
    "\n",
    "The objective of the univariate non-graphical EDA is to understand the sample distribution and also to make some initial conclusions about population distributions. Outlier detection is also a part of this analysis.\n",
    "\n",
    "**ii. Multivariate non-graphical EDA**\n",
    "\n",
    "Multivariate non-graphical EDA techniques show the relationship between two or more variables in the form of either cross-tabulation or statistics.\n",
    "\n",
    "**iii. Univariate graphical EDA**\n",
    "\n",
    "In addition to finding the various sample statistics of univariate distribution (discussed above), we also look graphically at the distribution of the sample. The non-graphical methods are quantitative and objective. They do not give full picture of the data. Hence, we need graphical methods, which are more qualitative in nature and presents an overview of the data.\n",
    "\n",
    "**iv. Multivariate graphical EDA**\n",
    "\n",
    "There are several useful multivariate graphical EDA techniques, which are used to look at the distribution of multivariate data. These are as follows:-\n",
    "\n",
    "Side-by-Side Boxplots\n",
    "\n",
    "Scatterplots\n",
    "\n",
    "Heat Maps and 3-D Surface Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae722af-5fee-43ed-a957-77f518831b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bada291-cd3c-4f54-bb2f-c16f0692e786",
   "metadata": {},
   "source": [
    "Enough of theory, now let the journey begin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf6372-78af-4fc5-9280-9408c11741c6",
   "metadata": {},
   "source": [
    "The first step in the EDA journey is to import the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1456e8-9c8e-442d-aacf-295bf5f28d88",
   "metadata": {},
   "source": [
    "## 4. Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0451f14-9857-4b18-a554-6c37876e8d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6749547d-4b4c-4c11-b476-fe48df8d8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5acec975-d095-4952-a59b-69dfcd50ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e186a23-0bc3-4254-8bf7-780af2457aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')# ignore warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1fe16-09bf-4a17-b91e-da28bd4096c4",
   "metadata": {},
   "source": [
    "I have imported the libraries. The next step is to import the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3b335-9609-4455-92ae-350e43b931ff",
   "metadata": {},
   "source": [
    "## 5. Import dataset ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3120c94-bd9e-44c9-9cff-7dffe3cf3269",
   "metadata": {},
   "source": [
    "I will import the dataset with the usual pandas read_csv() function which is used to import CSV (Comma Separated Value) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02cf3719-3432-4ef4-b895-feb8f756a14d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/heart-disease-uci/heart.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/heart-disease-uci/heart.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/heart-disease-uci/heart.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbc5fa-c88e-43d5-9ebe-661e04747eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
